================================================================================
ARK Big Ideas 2026 - Chapter 02: AI Infrastructure (Deep Dive Data)
페이지: 19-24
================================================================================

[투자자를 위한 상세 데이터 시트]

1. 시장 규모 및 투자 전망 (Market Sizing & Investment)
--------------------------------------------------------------------------------
*   **데이터센터 시스템 투자 (Data Center Systems Investment)**
    *   2025년: ~$500 Billion (2012-2023 평균의 약 2.5배)
    *   2030년 전망: ~$1.4 Trillion (약 1,900조원)
    *   성장률 (CAGR): 29% (ChatGPT 이전 5% 대비 6배 가속)
    *   세부 분야별 2030년 투자액 추정 (차트 기반):
        *   Compute (연산 장치): ~$1.1 Trillion (가장 큰 비중)
        *   Networking (네트워크): ~$200 Billion
        *   Storage (스토리지): ~$100 Billion

*   **Hyperscaler 설비투자 (Capex)**
    *   2021년: $135 Billion
    *   2026년 전망: >$500 Billion (2021년 대비 3.7배)
    *   투자 강도 (Capex/GDP): 2025년 기준 약 0.6% (1998년 닷컴 버블 정점과 유사)
    *   **투자 포인트**: 투자는 버블기 수준이나, P/E 비율은 당시(60~100x)보다 훨씬 낮은 30x 수준(Mag 6 기준)으로 거품론에 대한 반박 근거.

2. 비용 효율성 및 기술 경제학 (Unit Economics)
--------------------------------------------------------------------------------
*   **추론 비용 (Inference Costs) - 100만 토큰당 가격**
    *   **o1-preview (2024.09)**: ~$28.90
    *   **o1 (2024.12)**: ~$25.00
    *   **DeepSeek R1 (2025.01)**: ~$5.00 (급격한 하락 시작)
    *   **gpt-oss-20B (2025.08)**: ~$0.10 (1년 만에 99% 이상 하락)
    *   **결과**: 비용이 1/100로 줄어들며 수요 폭발. OpenRouter 토큰 처리량이 2024년 12월 대비 2026년 1월 25배 증가 (월 3,000억 -> 8조 토큰 추정).

3. AI 칩 성능 및 경제성 비교 (Chip Specs & TCO)
--------------------------------------------------------------------------------
보고서에 명시된 주요 AI 가속기 스펙 및 시간당 총 소유 비용(TCO) 비교.

| 모델명 | 제조사 | 출시일 | 메모리 (HBM) | 전력 (TDP) | 시간당 비용 (TCO) | 가성비 (Small Model) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **H200** | Nvidia | Q2 2024 | 141 GB | 700 W | **$1.41** | 15 (기준) |
| **B200** | Nvidia | Q1 2025 | 192 GB | 1000 W | **$1.95** | 32 (2배 효율) |
| **GB200** | Nvidia | Q1 2025 | 192 GB | 1200 W | **$2.21** | - |
| **MI300X** | AMD | Q4 2023 | 192 GB | 750 W | **$1.13** | 15 (H200과 유사) |
| **MI355X** | AMD | Q2 2025 | **288 GB** | 1400 W | **$1.49** | **38 (최고 효율)** |
| **TPU v7** | Google | Q4 2025 | 192 GB | 980 W | **$1.28** | - |

*   **투자 인사이트**:
    *   **AMD MI355X**: 메모리 용량(288GB)과 가격($1.49) 대비 성능(38)에서 Nvidia B200(32)을 앞서는 가성비 보여줌. 추론 시장에서의 점유율 확대 가능성.
    *   **Nvidia**: 여전히 학습(Training) 및 대형 모델(Large Model) 추론에서 Grace Blackwell(GB200)로 우위 유지.

4. 서버 시장 점유율 전망 (Server Market Share)
--------------------------------------------------------------------------------
*   **2030년 서버 시장 구성 (매출 기준 추정)**
    *   **ASIC (주문형 반도체)**: ~45% (Broadcom, Marvell, Amazon, Google 등) - 가장 빠르게 성장.
    *   **GPU**: ~40% (Nvidia, AMD) - 여전히 강력하지만 ASIC에 일부 파이 내어줌.
    *   **Traditional (CPU)**: ~15% (Intel, AMD) - 비중 축소.

5. 관련 기업 및 티커 (Tickers & Context)
--------------------------------------------------------------------------------
*   **Nvidia (NVDA)**: GPU 시장 85% 점유, 75% 마진. B200/GB200으로 리더십 방어.
*   **AMD (AMD)**: MI300/MI355 시리즈로 '가성비 추론' 시장 공략. Nvidia의 유일한 상용 GPU 경쟁자.
*   **Broadcom (AVGO)**: ASIC 설계의 강자. Google TPU, Meta MTIA 등 빅테크 자체 칩 설계 파트너.
*   **Amazon (AMZN)**: AWS 인프라 + 자체 칩(Trainium/Inferentia)으로 비용 절감 및 수직 계열화.
*   **Alphabet (GOOGL)**: TPU v7 자체 칩 보유. Gemini 모델 구동 비용 최적화.
*   **TSMC (TSM)**: 모든 고성능 AI 칩(Nvidia, AMD, Google, Amazon 등)의 생산 기지.
*   **Microsoft (MSFT)**: Azure Maia 칩 개발 및 OpenAI 인프라 투자.

6. 리스크 요인 (Risk Factors)
--------------------------------------------------------------------------------
*   **투자 회수(ROI) 지연**: 빅테크의 연간 $500B Capex가 실제 AI 매출로 회수되지 않을 경우, 2026-2027년경 투자 급감(Capex Cut) 가능성.
*   **전력 부족**: 데이터센터 전력 소비 급증으로 인한 전력망 병목 현상이 인프라 확장의 최대 걸림돌 (Chapter 11 참조).
